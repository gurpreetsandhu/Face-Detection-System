{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TripletFaceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, csv_name, num_triplets, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.df = pd.read_csv(csv_name)\n",
    "        self.num_triplets = num_triplets\n",
    "        self.transform = transform\n",
    "        self.training_triplets = self.generate_triplets(self.df, self.num_triplets)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_triplets(df, num_triplets):\n",
    "\n",
    "        def make_dictionary_for_face_class(df):\n",
    "\n",
    "            '''\n",
    "              - face_classes = {'class0': [class0_id0, ...], 'class1': [class1_id0, ...], ...}\n",
    "            '''\n",
    "            face_classes = dict()\n",
    "            for idx, label in enumerate(df['class']):\n",
    "                if label not in face_classes:\n",
    "                    face_classes[label] = []\n",
    "                face_classes[label].append(df.iloc[idx, 0])\n",
    "            return face_classes\n",
    "\n",
    "        triplets = []\n",
    "        classes = df['class'].unique()\n",
    "        face_classes = make_dictionary_for_face_class(df)\n",
    "\n",
    "        for _ in range(num_triplets):\n",
    "\n",
    "            '''\n",
    "              - randomly choose anchor, positive and negative images for triplet loss\n",
    "              - anchor and positive images in pos_class\n",
    "              - negative image in neg_class\n",
    "              - at least, two images needed for anchor and positive images in pos_class\n",
    "              - negative image should have different class as anchor and positive images by definition\n",
    "            '''\n",
    "\n",
    "            pos_class = np.random.choice(classes)\n",
    "            neg_class = np.random.choice(classes)\n",
    "            while len(face_classes[pos_class]) < 2:\n",
    "                pos_class = np.random.choice(classes)\n",
    "            while pos_class == neg_class:\n",
    "                neg_class = np.random.choice(classes)\n",
    "\n",
    "            pos_name = df.loc[df['class'] == pos_class, 'name'].values[0]\n",
    "            neg_name = df.loc[df['class'] == neg_class, 'name'].values[0]\n",
    "\n",
    "            if len(face_classes[pos_class]) == 2:\n",
    "                ianc, ipos = np.random.choice(2, size=2, replace=False)\n",
    "            else:\n",
    "                ianc = np.random.randint(0, len(face_classes[pos_class]))\n",
    "                ipos = np.random.randint(0, len(face_classes[pos_class]))\n",
    "                while ianc == ipos:\n",
    "                    ipos = np.random.randint(0, len(face_classes[pos_class]))\n",
    "            ineg = np.random.randint(0, len(face_classes[neg_class]))\n",
    "\n",
    "            triplets.append(\n",
    "                [face_classes[pos_class][ianc], face_classes[pos_class][ipos], face_classes[neg_class][ineg],\n",
    "                 pos_class, neg_class, pos_name, neg_name])\n",
    "\n",
    "        return triplets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        anc_id, pos_id, neg_id, pos_class, neg_class, pos_name, neg_name = self.training_triplets[idx]\n",
    "\n",
    "        anc_img = os.path.join(self.root_dir, str(pos_name), str(anc_id) + '.png')\n",
    "        pos_img = os.path.join(self.root_dir, str(pos_name), str(pos_id) + '.png')\n",
    "        neg_img = os.path.join(self.root_dir, str(neg_name), str(neg_id) + '.png')\n",
    "\n",
    "        anc_img = io.imread(anc_img)\n",
    "        pos_img = io.imread(pos_img)\n",
    "        neg_img = io.imread(neg_img)\n",
    "\n",
    "        pos_class = torch.from_numpy(np.array([pos_class]).astype('long'))\n",
    "        neg_class = torch.from_numpy(np.array([neg_class]).astype('long'))\n",
    "\n",
    "        sample = {'anc_img': anc_img, 'pos_img': pos_img, 'neg_img': neg_img, 'pos_class': pos_class,\n",
    "                  'neg_class': neg_class}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['anc_img'] = self.transform(sample['anc_img'])\n",
    "            sample['pos_img'] = self.transform(sample['pos_img'])\n",
    "            sample['neg_img'] = self.transform(sample['neg_img'])\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.training_triplets)\n",
    "\n",
    "\n",
    "def get_dataloader(train_root_dir, valid_root_dir,\n",
    "                   train_csv_name, valid_csv_name,\n",
    "                   num_train_triplets, num_valid_triplets,\n",
    "                   batch_size, num_workers):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])}\n",
    "\n",
    "    face_dataset = {\n",
    "        'train': TripletFaceDataset(root_dir=train_root_dir,\n",
    "                                    csv_name=train_csv_name,\n",
    "                                    num_triplets=num_train_triplets,\n",
    "                                    transform=data_transforms['train']),\n",
    "        'valid': TripletFaceDataset(root_dir=valid_root_dir,\n",
    "                                    csv_name=valid_csv_name,\n",
    "                                    num_triplets=num_valid_triplets,\n",
    "                                    transform=data_transforms['valid'])}\n",
    "\n",
    "    dataloaders = {\n",
    "        x: torch.utils.data.DataLoader(face_dataset[x], batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        for x in ['train', 'valid']}\n",
    "\n",
    "    data_size = {x: len(face_dataset[x]) for x in ['train', 'valid']}\n",
    "\n",
    "    return dataloaders, data_size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
